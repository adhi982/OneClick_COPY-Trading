Project Blueprint: The Aptos Order-Book Explorer
Introduction: Architecting a Professional-Grade DeFi Analytics Dashboard
Executive Summary
This report provides a comprehensive, phase-wise Minimum Viable Product (MVP) blueprint for the 'Order-Book Explorer,' a sophisticated on-chain analytics dashboard for the Aptos blockchain. The plan is specifically tailored for a competitive hackathon environment, prioritizing rapid development using free, high-quality tools while integrating unique, professional-grade analytical features designed to secure a winning position. The project's core objective is to deliver a tool that offers traders deep, actionable insights into on-chain order flow, liquidity dynamics, and potential market shifts, leveraging the high-performance capabilities of the Aptos network.   

Project Vision
The Order-Book Explorer will transcend being a simple data visualization tool. It will serve as a critical market intelligence platform, moving beyond the mere presentation of raw data to the generation of predictive, analytical insights. By focusing on the transformation of on-chain events into actionable intelligence, the Explorer will empower traders to understand market dynamics with a clarity typically reserved for institutional-grade platforms. This vision is aligned with the evolution of Aptos itself into a "Global Trading Engine," demanding equally sophisticated tooling for its participants.   

Table: Phase-wise Deliverables Matrix
Phase	Title	Core Objectives	Key Tasks	Expected Deliverables
1	Project Scaffolding & Environment Configuration	Establish a functional baseline application and development environment.	Install prerequisites, scaffold the project using create-aptos-dapp, configure environment variables, and integrate the wallet adapter.	A running Next.js application on localhost that can connect to the Petra wallet on the Aptos Devnet.
2	Backend Infrastructure & Data Ingestion	Build the server-side logic to fetch and process on-chain order book data.	Architect the data pipeline, develop GraphQL queries for the Aptos Indexer, and implement a rapid polling mechanism for real-time updates.	A set of Next.js API routes that serve historical trade data and near-real-time order book state from the chosen DEX protocol.
3	Frontend Development & Data Visualization	Construct a polished, intuitive, and highly functional user interface.	Design the dashboard layout, integrate TradingView Lightweight Charts for price data, and build interactive components for the order book and trade feed.	A fully interactive frontend that visualizes live price charts, order book depth, and a streaming feed of recent trades.
4	The Winning Edge: Sophisticated Analytics	Implement unique, derivative analytical features that provide a competitive advantage.	Develop backend logic for calculating real-time VWAP, an Order Book Imbalance Ratio, and a CUSUM-inspired Change Point Detection algorithm.	Visualization of VWAP as a chart overlay, a gauge for order book imbalance, and markers on the price chart indicating significant market pressure shifts.
5	Integration, Deployment, & Pitch Strategy	Finalize the application, deploy it to a public URL, and prepare a compelling presentation.	(Optional) Develop and deploy a simple Move smart contract for user preferences. Deploy the application to Vercel. Craft the hackathon pitch.	A publicly accessible, deployed dApp. A polished pitch deck and demonstration script highlighting the project's unique value proposition.

Export to Sheets
Section 1: Foundational Architecture and Technology Stack
1.1. Core Philosophy: From Raw Data to Actionable Intelligence
The foundational principle of the Order-Book Explorer is that raw on-chain data, while transparent, is not inherently useful. Its value is unlocked through aggregation, calculation, and contextual visualization. A simple display of bids and asks provides a snapshot; a calculated indicator of imbalance provides insight into market pressure. A stream of executed trades is noise; a Volume-Weighted Average Price (VWAP) derived from that stream provides a benchmark for fair value. This project is architected around this philosophy of transformation. Every feature is designed to move the user up the information value chain, from observing raw data points to understanding complex market dynamics and identifying potential opportunities. This approach is what will elevate the Explorer from a utility to an indispensable intelligence tool.

1.2. Technology Stack Selection and Rationale
The selection of technologies for a time-constrained hackathon must prioritize speed, stability, and power, while adhering to the constraint of using free-tier services. The chosen stack is a curated collection of best-in-class tools from the Aptos ecosystem and the broader web development community, designed for maximum development velocity.

The Aptos blockchain, specifically its Devnet, serves as the foundational layer. Its architecture, featuring the Move language and a parallel execution engine (Block-STM), is engineered for high throughput and low latency, making it an ideal environment for building high-performance financial applications.   

To accelerate development, the project will be bootstrapped using the official create-aptos-dapp CLI tool. This tool is a significant force multiplier, generating a pre-configured, full-stack application that includes a Move contract directory, a React/Vite frontend, the Aptos Wallet Adapter for seamless wallet connections, and essential npm scripts for compiling and deploying smart contracts. This effectively bypasses hours of manual setup, allowing the team to focus immediately on feature development.   

The frontend will be built with React and Next.js, leveraging the structure provided by the scaffolding tool. Next.js is particularly crucial for its API routes, which will house the project's server-side logic, creating a robust Backend-for-Frontend (BFF) pattern. For data visualization, TradingView's Lightweight Charts library is the optimal choice. It is open-source under an Apache 2.0 license for personal projects, exceptionally small (around 35 KB), and engineered for high-performance rendering of large, streaming datasets—a perfect fit for financial data applications.   

Finally, for deployment, the Vercel Hobby plan offers a seamless, zero-configuration experience for Next.js applications, complete with a generous free tier and automated CI/CD. This allows for rapid and continuous deployment throughout the hackathon, facilitating quick iterations and testing.   

Table: Technology Stack & Rationale
Component	Technology	Rationale	Supporting Documents
Blockchain	Aptos Devnet	High-performance Layer 1 with low fees, parallel execution, and a strong developer focus. Devnet provides a free and stable testing environment.	
Scaffolding	create-aptos-dapp	Official CLI tool for rapid full-stack dApp creation. Provides pre-configured project structure, wallet adapter, and Move commands, saving significant setup time.	
Frontend	React / Next.js / Vite	Modern, high-performance web framework provided by the scaffolding tool. Next.js API routes are essential for server-side data processing.	
Charting	TradingView Lightweight Charts	Open-source, lightweight (35 KB), and high-performance library specifically designed for interactive financial charts with real-time data streaming.	
UI Components	shadcn/ui + Tailwind CSS	Included with create-aptos-dapp, providing a modern, utility-first approach to building a clean and professional-looking UI quickly.	
Deployment	Vercel (Hobby Tier)	Offers a generous free tier for non-commercial projects with seamless, automated deployment for Next.js applications.	
  
1.3. On-Chain Data Source Analysis and Strategy
Selecting the correct on-chain data source is the most critical strategic decision for this project. The Aptos DeFi ecosystem is evolving rapidly, and aligning with its future trajectory is paramount for creating a relevant and impressive hackathon entry.

Early Aptos DEX protocols, such as Econia, are no longer actively maintained and represent the previous generation of the ecosystem's DeFi infrastructure. Building on such a protocol would demonstrate a lack of current ecosystem awareness. The strategic direction of Aptos is now firmly focused on establishing itself as a "Global Trading Engine". This initiative is spearheaded by the development of a framework-level Central Limit Order Book (CLOB), a foundational piece of infrastructure designed to unify liquidity and provide CEX-level performance directly on-chain.   

The primary engine for this new CLOB is Decibel, a high-performance, fully on-chain trading engine incubated by Aptos Labs. Decibel aims to unify spot, perpetuals, and yield products into a single, composable system, serving as the core execution layer for Aptos DeFi. Therefore, the strategic choice is clear: the Order-Book Explorer must target the    

Decibel trading engine on the Aptos Devnet. This choice aligns the project with the most advanced and forward-looking technology in the ecosystem, showcasing a deep understanding of its roadmap. While other high-volume DEXs like Hyperion exist and are significant players , Decibel's role as the native engine for the framework-level CLOB makes it the superior and more technically ambitious target.   

This strategic choice, however, introduces a significant technical challenge. As a cutting-edge protocol recently launched on Devnet (August 2025) , Decibel is unlikely to have mature, publicly documented developer SDKs or dedicated APIs for querying granular order book data. A standard approach of querying a simple REST or GraphQL endpoint for order book depth is not feasible. This necessitates a more sophisticated data retrieval strategy.   

The plan will employ a two-pronged approach to data ingestion that bypasses the need for a dedicated protocol API:

For Historical Trade Data: The Aptos Indexer will be used. It provides a powerful GraphQL API to query historical on-chain transactions. By filtering for transactions interacting with the Decibel smart contract address, a complete history of trades can be reconstructed.   

For Live Order Book State: The Aptos TypeScript SDK will be used to directly read the state of the Decibel smart contract's data structures (e.g., resources holding the bid/ask trees) from an Aptos Fullnode. This is a more advanced technique that interacts with the blockchain at a lower level but is robust and not dependent on any intermediary API.   

This hybrid data strategy not only solves the data accessibility problem but also demonstrates a high level of technical proficiency, a key factor in a competitive hackathon environment.

Section 2: Phase 1 - Project Scaffolding and Environment Configuration
2.1. Prerequisites and Developer Toolchain Installation
Before any project-specific work can begin, the local development environment must be configured with the necessary toolchain. This foundational step ensures that all subsequent phases can proceed without delays caused by missing dependencies. The required tools are standard for modern web and blockchain development.

First, Node.js is essential, as it provides the runtime for the Next.js frontend and the npm package manager for handling project dependencies. A version compatible with the create-aptos-dapp tool is required, typically the latest LTS release. Second, Python is a prerequisite for some underlying blockchain tools and scripts; a version of 3.6 or higher is specified. Third, Git must be installed for version control and for cloning necessary repositories.   

On the blockchain-specific side, the Aptos CLI is a critical tool. While create-aptos-dapp provides convenient npm scripts for many actions, the CLI is invaluable for direct, manual interaction with the blockchain, such as querying account resources or deploying modules for debugging purposes. Finally, for user interaction with the deployed dApp, a browser-based Aptos wallet is necessary. The Petra wallet is the officially supported wallet by Aptos Labs and is recommended for this project. It will be used to connect to the dApp, sign transactions, and manage the user's on-chain identity.   

2.2. Rapid Scaffolding with create-aptos-dapp
The cornerstone of Phase 1 is the use of the create-aptos-dapp scaffolding tool. This command-line utility is designed to eliminate the time-consuming and error-prone process of manually setting up a full-stack decentralized application on Aptos. By automating the creation of the project structure, dependency management, and initial configuration, it allows the development team to transition from an empty directory to a running application in minutes.   

The process is initiated by running a single command in the terminal: npx create-aptos-dapp@latest. This command fetches and executes the latest version of the scaffolding script. The script will then present a series of prompts to customize the project:   

Project Name: order-book-explorer

Template Selection: The tool offers several templates, such as "NFT minting dapp" or "Fungible Asset Template". For this project, the    

"Boilerplate Template" is the correct choice. It provides the most minimal setup: an empty Move contract and a UI that only connects to a wallet. This clean slate is ideal, as it avoids the need to remove irrelevant NFT or token-minting logic.   

Network Choice: The prompt will ask whether to configure the project for Mainnet or Devnet. Devnet must be selected for this hackathon project.   

Upon completion, the tool generates a new directory containing a fully structured project. This includes a move/ directory for smart contracts, a standard Next.js src/ directory for the frontend, and a package.json file with pre-configured scripts like npm run dev (to start the local development server) and npm run move:compile (to compile the Move contracts).   

2.3. Environment Configuration and Wallet Adapter Integration
With the project structure in place, the final step of this phase is to perform initial configuration and verify the core functionality. The scaffolding tool creates a .env file in the project root. This file is used to store environment variables, such as the address of the deployed Move module. While our initial smart contract is empty, it is good practice to perform an initial compilation and deployment to Devnet using the provided scripts (   

npm run move:init, npm run move:compile, npm run move:publish) to obtain a module address and populate this file. This ensures the entire end-to-end workflow is functional from the start.

The most critical verification for this phase is the wallet connection. The create-aptos-dapp tool pre-integrates the Aptos Wallet Adapter, which handles the complex logic of detecting installed wallets (like Petra) and managing the connection state. By starting the development server with    

npm run dev and navigating to http://localhost:5173, the boilerplate application should display a "Connect Wallet" button. Clicking this button should trigger the Petra wallet extension, prompting the user to approve the connection. A successful connection confirms that the foundational layer of the dApp is working correctly and ready for the development of backend and frontend features in the subsequent phases.   

Section 3: Phase 2 - Backend Infrastructure and On-Chain Data Ingestion
3.1. Architecting the Data Pipeline: From Blockchain to Browser
The data pipeline is the central nervous system of the Order-Book Explorer. Its design must be robust, efficient, and capable of delivering data from the Aptos blockchain to the user's browser with minimal latency. The architecture will follow a Backend-for-Frontend (BFF) pattern, utilizing Next.js API Routes as a dedicated server-side layer that sits between the blockchain data sources and the client-side React application.

The data flow is as follows:

Data Source (Aptos Blockchain): The raw data originates from two primary sources: the Aptos Indexer for historical transaction data and an Aptos Fullnode for real-time contract state. The target is the on-chain data structures of the Decibel trading engine.

Data Ingestion (Next.js API Routes): A set of API endpoints created within the pages/api/ directory will be responsible for all interactions with the blockchain. For example, an endpoint like /api/trades will query the Aptos Indexer, while an endpoint like /api/orderbook will use the Aptos TS SDK to query a fullnode.

Data Processing & Transformation: This server-side layer will not merely proxy data. It will perform crucial transformations. For instance, it will parse raw transaction event data to calculate standardized fields like price and volume. It will also aggregate data to create OHLCV (Open, High, Low, Close, Volume) candles for the charting library.

Data Consumption (React Frontend): The frontend application will make simple HTTP requests to its own backend API routes (e.g., fetch('/api/trades')). It will receive clean, structured, and ready-to-render JSON data.

This BFF architecture provides several key advantages. It abstracts the complexity of blockchain interaction away from the frontend, leading to cleaner client-side code. It secures sensitive information, such as API keys for third-party indexer services, by keeping them on the server. Most importantly, it allows for server-side caching and data processing, reducing the computational load on the client and improving the overall performance and responsiveness of the application. This pattern is a standard practice for building robust web applications and is fully supported by the Next.js framework.   

3.2. Mastering the Aptos Indexer: Advanced GraphQL for Trade History
The Aptos Indexer is a powerful tool that provides indexed, queryable data from the blockchain via a GraphQL API. This is the ideal source for fetching historical and recent trade data for the Decibel protocol. Instead of running a dedicated indexer, the project will utilize a free, publicly available endpoint from a provider like BlockEden or Shinami to ensure rapid setup.   

The core task is to construct GraphQL queries that retrieve all user transactions interacting with the Decibel smart contract. This involves filtering the user_transactions table by the contract's address and the specific entry functions that correspond to trade executions (e.g., place_market_order). The query will need to request the transaction    

version, timestamp, and the events payload.

However, the raw event data from a DEX trade transaction typically does not contain explicit price and volume fields. Instead, it will contain information about the assets being exchanged, such as the amount of the input asset and the amount of the output asset. A critical function of the backend API route will be to parse this event data and perform the necessary calculations. For a trade of Token A for Token B, the effective price can be calculated as `$Price = \frac{\text{Amount of Token B}}{\text{Amount of Token A}}$$. The volume is the total value of the trade, typically denominated in the quote currency (e.g., USDC). This server-side transformation is essential for providing the clean, standardized data required by the frontend charting and trade feed components.

To further accelerate development, the backend will also be responsible for aggregating these individual trades into time-based OHLCV candles (e.g., 1-minute, 5-minute, 1-hour). This pre-processing on the server prevents the client from having to download thousands of individual trades and perform the aggregation itself, leading to a much faster and more efficient user experience.

Table: Aptos Indexer GraphQL Query Library (Conceptual Examples)
Query Name	Description	Conceptual GraphQL Query
GetRecentTrades	Fetches the last 100 trade transactions for the Decibel protocol.	query GetRecentTrades { user_transactions( where: { entry_function_id_str: {_eq: "DECI_ADDRESS::market::place_market_order"} }, order_by: {version: desc}, limit: 100 ) { version events { data } } }
GetHistoricalTrades	Fetches trade transactions within a specific version range for historical chart data.	query GetHistoricalTrades($start_version: bigint, $end_version: bigint) { user_transactions( where: { entry_function_id_str: {_eq: "DECI_ADDRESS::market::place_market_order"}, version: {_gte: $start_version, _lte: $end_version} }, order_by: {version: asc} ) { version events { data } } }

Export to Sheets
Note: The exact entry_function_id_str and events.data structure must be determined by inspecting actual Decibel transactions on an Aptos explorer.

3.3. Engineering Real-Time Updates via Server-Side Logic
Achieving true real-time data streaming in a hackathon, especially for a new protocol without a public WebSocket API, requires a pragmatic approach. The solution is to implement a rapid server-side polling mechanism that simulates a real-time feed.

An API route, such as /api/updates, will be created in Next.js. The frontend will call this endpoint at a regular interval (e.g., every 2-3 seconds). Each time this endpoint is hit, it will perform two key actions:

Query for New Trades: It will execute a GraphQL query against the Aptos Indexer to fetch any transactions that have occurred since the last poll. This provides the data for the live trade feed and for updating the most recent price candle.

Query for Order Book State: It will use the Aptos TypeScript SDK to make a direct call to an Aptos Fullnode, reading the current state of the resources within the Decibel smart contract that store the bid and ask data.

This polled data (new trades and the latest order book snapshot) will be packaged into a single JSON response and sent back to the client. While this is technically polling, the high performance of the Aptos network and indexers means that a 2-3 second interval can provide a user experience that feels very close to real-time.

This architecture is also designed for future enhancement. The server-side logic is centralized in one API route. If a WebSocket or Transaction Stream Service  feed for Decibel becomes available, the polling logic can be replaced with a WebSocket client on the server, which would then push data to the connected frontends. The frontend code would require minimal changes, demonstrating sound and forward-thinking architectural design. This approach of creating a webhook-like endpoint within Next.js is a standard and robust pattern.   

Section 4: Phase 3 - Frontend Development and Advanced Data Visualization
4.1. UI/UX Blueprint: A Professional Trader's Dashboard
The user interface of the Order-Book Explorer must be clean, data-dense, and intuitive, mirroring the layout of professional trading terminals. The goal is to present a large amount of complex information in a manner that is immediately scannable and understandable. The design will be built around a multi-panel layout, constructed using modern and efficient styling tools. The create-aptos-dapp scaffold provides a project pre-configured with Tailwind CSS and the shadcn/ui component library, which are ideal for rapidly building a polished and responsive interface.   

The main components of the dashboard will be:

Top Navigation Bar: A simple bar containing the project logo, a market selector dropdown (e.g., "APT/USDC"), and the "Connect Wallet" button.

Main Chart Panel (Center): This will be the largest component, occupying the central area of the screen. It will house the TradingView Lightweight Chart, displaying price data and analytical overlays.

Order Book Panel (Right): A vertically oriented panel displaying the live order book. It will be split into two sections: asks (sell orders) in red at the top, and bids (buy orders) in green at the bottom, with the current market price displayed in the middle. Each row will show price, size, and a cumulative size. A subtle background bar will visualize the depth at each price level.

Recent Trades Panel (Bottom): A horizontally oriented panel below the main chart that shows a live-scrolling feed of the most recent market trades. Each row will display the time, price, and size of the trade, color-coded green for buys and red for sells.

This layout is a standard convention in financial applications because it works effectively. It allows a trader to correlate price action on the chart with the underlying liquidity in the order book and the flow of executed trades, all within a single view.

4.2. Core Visualization: Integrating and Powering TradingView Lightweight Charts
The heart of the dashboard is the interactive price chart. TradingView's Lightweight Charts library is perfectly suited for this task due to its high performance and simple API. The integration will be encapsulated within a reusable React component,    

<TradingChart>.

The implementation will follow a standard React pattern for integrating third-party libraries that manipulate the DOM :   

DOM Reference: A useRef hook (chartContainerRef) will be used to get a stable reference to the div element that will contain the chart.

Initialization and Data Handling: A useEffect hook will contain all the logic for creating, updating, and cleaning up the chart instance. This hook will be triggered whenever the input data changes.

Initial Data Load: When the <TradingChart> component first mounts, the useEffect hook will make an asynchronous call to our backend API route (e.g., /api/ohlcv) to fetch a substantial amount of historical OHLCV data. Once this data is received, the chart will be initialized using createChart(), a candlestick series will be added using chart.addCandlestickSeries(), and the historical data will be populated using series.setData(historicalData).

Real-Time Updates: The useEffect hook will also establish a setInterval function to periodically poll the /api/updates endpoint. This endpoint will return the latest trade data, which will be processed into a new or updated candle. The series.update(newCandleData) method will then be called to append this new information to the chart. This creates the effect of a live, streaming chart without requiring a full page reload.   

Cleanup: The useEffect hook will return a cleanup function. This function is critical for preventing memory leaks and will be responsible for removing the chart instance (chart.remove()) and clearing the interval when the component unmounts.

This approach ensures a clean separation of concerns, with the <TradingChart> component being solely responsible for rendering the chart based on the data it receives as props.

4.3. Building the Interactive Order Book and Trade Feed Components
Complementing the main chart are the live order book and trade feed components, which provide crucial context about market liquidity and activity.

The Order Book Component will be a React component that fetches its data from the /api/updates endpoint. It will receive two arrays, one for bids and one for asks. The component will map over these arrays to render two lists of orders. Each list item will display the price, the quantity of the asset available at that price, and the cumulative quantity. To enhance readability, a subtle colored background bar will be rendered behind each row, with its width proportional to the size of the order at that price level. This provides an immediate visual representation of market depth and highlights significant levels of supply or demand.

The Trade Feed Component will be a simpler component that also receives its data from the /api/updates endpoint, specifically the list of new trades that have occurred since the last poll. It will maintain an array of recent trades in its state. When new trades arrive, they will be prepended to this array, and the oldest trades will be removed to keep the list at a manageable size. The component will render this array as a scrolling list, with each row color-coded based on the trade direction (e.g., using a green text color for buys and red for sells). This provides a constant, streaming view of market activity, allowing users to see the size and frequency of trades as they happen.

Section 5: Phase 4 - The Winning Edge: Sophisticated On-Chain Analytics
This phase is dedicated to implementing the unique, high-value features that will differentiate the Order-Book Explorer from standard data viewers. These are not just additional data points; they are calculated, derivative metrics that provide deep, actionable insights into market behavior. The logic for these calculations will reside in the Next.js backend, which will process the raw on-chain data and deliver the results to the frontend for visualization.

5.1. Feature Deep Dive: Real-Time Volume-Weighted Average Price (VWAP) Calculation and Visualization
Concept: The Volume-Weighted Average Price (VWAP) is a technical analysis indicator used on intraday charts that resets at the start of each new trading session. It is calculated by adding up the dollars traded for every transaction (price multiplied by the number of shares traded) and then dividing by the total shares traded. Unlike a simple moving average, VWAP gives more weight to price points with higher trading volume, making it a more accurate representation of the "true" average price over a period. Institutional traders often use VWAP as a benchmark to assess the quality of their execution.   

Implementation: The calculation for VWAP is cumulative over a defined period (e.g., a 24-hour cycle). The formula is:

VWAP= 
∑Volume
∑(Price×Volume)
​
 
Our Next.js backend will maintain two running totals that reset every 24 hours: a cumulative sum of (Price * Volume) and a cumulative sum of Volume. For every new trade received from the Aptos Indexer, the backend will update these sums. The Price and Volume for each trade will be derived from the raw transaction data as described in Section 3.2. After each update, the new VWAP value will be calculated and included in the real-time data payload sent to the frontend.

Visualization: The VWAP will be displayed as a smooth line overlay on the main TradingView price chart. A new line series will be added to the chart instance (chart.addLineSeries()). With each real-time update received from the backend, the frontend will call lineSeries.update() with the new timestamp and the corresponding VWAP value. This provides traders with a powerful visual benchmark, allowing them to see if the current price is trading above or below the volume-weighted average.

5.2. Feature Deep Dive: A Novel Order Book Imbalance Indicator
Concept: Order book imbalance is a measure of the disparity between the total volume of buy orders (bids) and sell orders (asks) in the order book. A significant imbalance indicates that one side of the market is more aggressive than the other, which can be a leading indicator of short-term price movements. For example, a large volume of bids relative to asks suggests strong buying pressure and a potential upward price move.   

Implementation: To create a simple yet effective indicator, we will calculate a Normalized Volume Imbalance Ratio. In the backend, with each poll of the order book state, we will fetch the top N price levels from both the bid and ask sides (e.g., N=20). We will then calculate the total volume for each side:

TotalBidVolume=∑ 
i=1
N
​
 BidVolume 
i
​
 

TotalAskVolume=∑ 
i=1
N
​
 AskVolume 
i
​
 

The imbalance ratio is then calculated as:

ImbalanceRatio= 
TotalBidVolume+TotalAskVolume
TotalBidVolume−TotalAskVolume
​
 
This formula normalizes the result to a range between -1 and +1. A value of +1 indicates extreme buying pressure (all volume is on the bid side), -1 indicates extreme selling pressure (all volume is on the ask side), and 0 represents a perfectly balanced book. This calculated ratio will be included in the real-time update payload.

Visualization: The Imbalance Ratio will be displayed in a dedicated widget below the main chart. This could be a simple horizontal bar that moves left (red) for negative imbalance and right (green) for positive imbalance, or a gauge-style component. This provides traders with an immediate, at-a-glance understanding of the current market sentiment as reflected in the order book's liquidity distribution.

5.3. Feature Deep Dive: CUSUM-Inspired Change Point Detection for Market Shift Alerts
Concept: The Cumulative Sum (CUSUM) algorithm is a sequential analysis technique used to monitor for changes in a process. We can adapt this powerful concept to our Order Book Imbalance indicator to detect not just the current state of pressure, but significant    

shifts in that pressure over time. The goal is to identify the precise moments when market sentiment undergoes a structural change, filtering out random noise and highlighting potentially actionable signals.

Implementation (Simplified for a Hackathon): This feature builds directly on the Imbalance Ratio calculated in the previous step. The backend will maintain a running, rolling "cumulative imbalance score."

Initialize a score variable, S, to 0.

For each new Imbalance Ratio, I 
t
​
 , received at time t, update the score: S 
t
​
 =S 
t−1
​
 +I 
t
​
 .

To keep the score relevant to recent activity, a decay factor or a rolling window can be applied. A simple approach is to reset the score to 0 if it crosses back over the zero line, so it only accumulates persistent one-sided pressure.

Define a threshold, θ. If ∣S 
t
​
 ∣>θ, a "change point event" is triggered. This signifies that a sustained and significant shift in order book pressure has occurred.

After triggering an event, the score S is reset to 0 to begin detecting the next shift.

Visualization: This is the most impactful part of the feature. When the backend detects a change point event, it will include a flag in the real-time update payload. The frontend, upon receiving this flag, will use the TradingView chart's API to place a visual marker directly on the price series at that specific time. For example, a green arrow below a candle could signify a positive change point (a shift towards buying pressure), while a red arrow above a candle could signify a negative one. This directly links a critical change in the underlying market microstructure (the order book) to a specific point in the price history, providing a powerful and unique analytical signal.

The synergy of these three features creates a compelling analytical narrative. The VWAP provides a baseline of value. The Imbalance Indicator shows the current pressure relative to that baseline. The Change Point Detection highlights the exact moments that pressure undergoes a significant and potentially trend-altering shift. This layered approach to analysis is what constitutes a professional-grade tool and will be a central theme of the project's final presentation.

Section 6: Phase 5 - Smart Contract Integration, Deployment, and Pitch Strategy
6.1. Optional Enhancement: On-Chain User Preferences Module
While the core functionality of the Order-Book Explorer is off-chain analysis of on-chain data, incorporating a simple smart contract interaction demonstrates full-stack dApp development capabilities. This optional enhancement involves creating a Move module that allows users to store their application preferences directly on the Aptos blockchain.

Functionality: The smart contract will provide a mechanism for users to save a list of their favorite trading pairs (identified by their on-chain addresses). This allows for a personalized experience, where the application could, for example, default to a user's favorite pair upon loading or provide a quick-access list.

Implementation:

Move Module: A new module will be created in the move/ directory. It will define a resource struct, UserPreferences, which will contain a vector<address> to store the market addresses. This resource will be stored under the user's account.

Entry Functions: The module will expose public entry functions that take a &signer as the first argument, allowing authenticated users to interact with their stored preferences. Key functions will include:

initialize(): Called once to create the UserPreferences resource under the user's account.

add_favorite(market_address: address): Adds a new market address to the user's vector.

remove_favorite(market_address: address): Removes a market address from the vector.

Frontend Integration: The frontend will include UI elements (e.g., a "star" icon next to the market selector) that, when clicked, trigger these on-chain actions. The Aptos TypeScript SDK will be used to construct the transaction payload, specifying the module address, function name, and arguments. The transaction will then be signed by the user's connected Petra wallet and submitted to the network using the    

aptos.signAndSubmitTransaction function. The application will then wait for the transaction to be confirmed before updating the UI state.   

This feature, while simple, effectively showcases an end-to-end understanding of the Aptos development stack, from writing and deploying a Move smart contract to interacting with it from a React frontend.

6.2. Deployment Checklist: Vercel and the Aptos Devnet
Deploying the application to a public URL is a critical final step for demonstration and judging. The combination of the create-aptos-dapp project structure and Vercel's platform makes this process straightforward.

Smart Contract Deployment:

Compile: Run npm run move:compile to compile the Move module(s) into bytecode.

Test: Run npm run move:test to execute any unit tests defined for the contract.

Publish: Run npm run move:publish to deploy the compiled modules to the Aptos Devnet. This command will use the private key of the account configured during npm run move:init.

Update Environment: Copy the new module address from the command line output and update the VITE_MODULE_ADDRESS variable in the .env file.   

Frontend Deployment to Vercel:

Vercel Account: Create a free Hobby account on Vercel and connect it to a GitHub account.

Push to GitHub: Initialize a Git repository in the project folder and push the code to a new repository on GitHub.

Import Project: In the Vercel dashboard, import the newly created GitHub repository. Vercel will automatically detect that it is a Next.js/Vite project and configure the build settings correctly.

Configure Environment Variables: In the Vercel project settings, add the environment variables from the local .env file. This is crucial for the deployed application to connect to the correct Aptos network and smart contracts.

Deploy: Trigger a deployment. Vercel will automatically build and deploy the application, providing a public URL upon completion.

It is important to be mindful of the usage limits of Vercel's free Hobby tier, particularly around serverless function execution time, as the rapid polling mechanism will generate consistent backend activity.   

6.3. Crafting the Winning Pitch: A Narrative for Hackathon Judges
The final presentation should be a compelling narrative, not just a feature list. The story should be clear, concise, and focused on the project's innovation and technical excellence.

The Core Narrative: "The Aptos ecosystem is rapidly maturing into a Global Trading Engine, with advanced new infrastructure like the Decibel on-chain order book. However, the tools available to traders have not kept pace. Existing explorers show you what has happened. The Order-Book Explorer is different. It's an intelligence dashboard that shows you what is happening now at the micro-level of the order book and provides unique, calculated indicators to help you anticipate what might happen next."

Key Differentiators to Emphasize in the Demo:

Future-Aligned Architecture: Start by highlighting the choice to build on Decibel, explaining its significance as the engine for the new framework-level CLOB. This shows strategic foresight and a deep understanding of the Aptos roadmap.

Sophisticated Technical Solution: Briefly mention the data ingestion challenge (new protocol, no API) and the solution (a hybrid approach of using the Indexer and reading contract state directly). This showcases advanced problem-solving skills.

Live Demo of Actionable Intelligence: This is the most crucial part.

Show the main chart with the VWAP overlay and explain its importance as a professional benchmark for fair value.

Point to the Order Book Imbalance gauge and explain how it provides a real-time sentiment reading.

The climax of the demo: show the Change Point Detection markers on the chart. Explain that these are not random signals but are algorithmically generated alerts that fire only when a significant, sustained shift in order book pressure occurs. This is the project's "alpha."

Polished and Professional UX: The live demo should be smooth and visually appealing. The real-time updates to the chart, order book, and trade feed will be impressive on their own.

Demonstration of Full-Stack Capability: If implemented, briefly showcase the on-chain user preferences feature by saving a favorite pair, proving end-to-end dApp development proficiency.

Conclusion: The Future Trajectory of the Order-Book Explorer
The MVP developed during this hackathon serves as a powerful proof-of-concept and a robust foundation for a full-featured, professional-grade trading analytics platform on Aptos. While the current implementation focuses on a single data source and a core set of unique indicators, its modular architecture and sophisticated data processing pipeline open up a clear and ambitious path for future development.

The immediate next step would be to expand data source integration. The Explorer could be enhanced to connect to other major Aptos DEXs, such as Hyperion and Merkle Trade, providing a unified, aggregated view of liquidity across the entire ecosystem. This would transform the tool into a comprehensive market-wide dashboard.

Building on this aggregated data, trade execution capabilities could be integrated directly into the interface. A "smart router" could leverage the platform's comprehensive view of liquidity to execute trades for users at the best possible price across all integrated venues.

Furthermore, the analytical engine can be significantly enhanced. The historical order book and trade data collected by the platform is an invaluable dataset for training machine learning models. Future versions could incorporate AI-driven predictive analytics, offering users signals based on learned patterns in order book behavior that are invisible to the human eye.

Finally, the transition from a rapid polling mechanism to a full WebSocket or Transaction Stream Service implementation would provide true, instantaneous real-time data updates, solidifying the platform's position as a CEX-level analytics tool. The Order-Book Explorer, as envisioned and architected in this plan, is not merely a hackathon project; it is the blueprint for an essential piece of infrastructure in the burgeoning Aptos DeFi ecosystem.

